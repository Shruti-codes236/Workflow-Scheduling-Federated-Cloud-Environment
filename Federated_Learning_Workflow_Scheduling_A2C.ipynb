{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f3f319d",
      "metadata": {
        "id": "0f3f319d"
      },
      "source": [
        "<div style=\"text-align:center\">\n",
        "    <h1>\n",
        "        Federated Learning-WorkFlow Scheduling: Advantage Actor-Critic (A2C)\n",
        "    </h1>\n",
        "</div>\n",
        "\n",
        "<br><br>\n",
        "The actor critic algorithm consists of two networks (the actor and the critic) working together to solve a particular problem. At a high level, the Advantage Function calculates the agentâ€™s TD Error or Prediction Error. The actor network chooses an action at each time step and the critic network evaluates the quality or the Q-value of a given input state."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82cd7986",
      "metadata": {
        "id": "82cd7986"
      },
      "source": [
        "## Importing the necessary software libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "956abf99",
      "metadata": {
        "id": "956abf99"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from gym import spaces\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "import multiprocessing as mp\n",
        "from torch.nn import Module\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9R8PSzeIza-",
        "outputId": "3fa5ed95-48be-4d1c-dd4d-9b9778c129b7"
      },
      "id": "T9R8PSzeIza-",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WorkFlow Parser**\n"
      ],
      "metadata": {
        "id": "Gf-jicRwInak"
      },
      "id": "Gf-jicRwInak"
    },
    {
      "cell_type": "code",
      "source": [
        "class Task():\n",
        "    def __init__(self,taskName,taskId, taskLength):\n",
        "\n",
        "        self.taskName=taskName\n",
        "        self.taskId=taskId\n",
        "        self.taskLength=taskLength\n",
        "        self.allocated = False\n",
        "        self.childList = []\n",
        "        self.parentList = []\n",
        "        self.fileList = []\n",
        "        self.impact = 0.0\n",
        "        self.taskFinishTime = -1.0\n",
        "        self.type = None\n",
        "        self.priority = 0\n",
        "        self.depth = 0\n",
        "\n",
        "    def setType(self, type):\n",
        "        self.type = type\n",
        "\n",
        "    def getType(self):\n",
        "        return self.type\n",
        "\n",
        "    def setPriority(self, priority):\n",
        "        self.priority = priority\n",
        "\n",
        "    def setDepth(self, depth):\n",
        "        self.depth = depth\n",
        "\n",
        "    def getPriority(self):\n",
        "        return self.priority\n",
        "\n",
        "    def getDepth(self):\n",
        "        return self.depth\n",
        "\n",
        "    def getChildList(self):\n",
        "        return self.childList\n",
        "\n",
        "    def setChildList(self, list):\n",
        "        self.childList = list\n",
        "\n",
        "    def setParentList(self, list):\n",
        "        self.parentList = list\n",
        "\n",
        "    def addChildList(self, list):\n",
        "        self.childList.extend(list)\n",
        "\n",
        "    def addParentList(self, list):\n",
        "        self.parentList.extend(list)\n",
        "\n",
        "    def getParentList(self):\n",
        "        return self.parentList\n",
        "\n",
        "    def addChild(self, task):\n",
        "        self.childList.append(task)\n",
        "\n",
        "    def addParent(self, task):\n",
        "        self.parentList.append(task)\n",
        "\n",
        "    def getFileList(self):\n",
        "        return self.fileList\n",
        "\n",
        "    def addFile(self, file):\n",
        "        self.fileList.append(file)\n",
        "\n",
        "    def setFileList(self, list):\n",
        "        self.fileList = list\n",
        "\n",
        "    def setImpact(self, impact):\n",
        "        self.impact = impact\n",
        "\n",
        "    def getImpact(self):\n",
        "        return self.impact\n",
        "\n",
        "    def setTaskFinishTime(self, time):\n",
        "        self.taskFinishTime = time\n",
        "\n",
        "    def getTaskFinishTime(self):\n",
        "        return self.taskFinishTime\n",
        "\n",
        "#depends on CloudLet\n",
        "    def getProcessingCost(self):\n",
        "        cost = self.getCostPerSec() * self.getActualCPUTime()\n",
        "        file_size = sum(file.getSize() / Consts.MILLION for file in self.getFileList())\n",
        "        cost += self.costPerBw * file_size\n",
        "        return cost"
      ],
      "metadata": {
        "id": "nGA5fI15Ipd3"
      },
      "id": "nGA5fI15Ipd3",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "from typing import List\n",
        "\n",
        "class FileType(Enum):\n",
        "    NONE = 0\n",
        "    INPUT = 1\n",
        "    OUTPUT = 2\n",
        "\n",
        "    def __new__(self, value):\n",
        "        obj = object.__new__(self)\n",
        "        obj._value_ = value\n",
        "        return obj\n",
        "\n",
        "class FileItem:\n",
        "    def __init__(self, name, size):\n",
        "        self.name = name\n",
        "        self.size = size\n",
        "        self.type = None\n",
        "\n",
        "    def setName(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def setSize(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def setType(self, file_type):\n",
        "        self.type = file_type\n",
        "\n",
        "    def getName(self):\n",
        "        return self.name\n",
        "\n",
        "    def getSize(self):\n",
        "        return self.size\n",
        "\n",
        "    def getType(self):\n",
        "        return self.type\n",
        "\n",
        "    def is_real_input_file(self, file_list):\n",
        "        if self.type == FileType.INPUT:\n",
        "            for another in file_list:\n",
        "                if another.get_name() == self.name and another.get_type() == FileType.OUTPUT:\n",
        "                    return False\n",
        "            return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "sBL6iepwIqQ5"
      },
      "id": "sBL6iepwIqQ5",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplicaCatalog:\n",
        "    class FileSystem:\n",
        "        SHARED = 'SHARED'\n",
        "        LOCAL = 'LOCAL'\n",
        "\n",
        "    fileName2File = {}\n",
        "    fileSystem = None\n",
        "    dataReplicaCatalog = {}\n",
        "\n",
        "\n",
        "    def init(self, fs):\n",
        "        self.fileSystem = fs\n",
        "        self.dataReplicaCatalog = {}\n",
        "        self.fileName2File = {}\n",
        "\n",
        "\n",
        "    def getFileSystem(self):\n",
        "        return self.fileSystem\n",
        "\n",
        "\n",
        "    def getFile(self, fileName):\n",
        "        return self.fileName2File.get(fileName)\n",
        "\n",
        "\n",
        "    def setFile(self, fileName, file):\n",
        "        self.fileName2File[fileName] = file\n",
        "\n",
        "\n",
        "    def containsFile(self, fileName):\n",
        "        return fileName in self.fileName2File\n",
        "\n",
        "\n",
        "    def getStorageList(self, file):\n",
        "        return self.dataReplicaCatalog.get(file, [])\n",
        "\n",
        "\n",
        "    def addFileToStorage(self, file, storage):\n",
        "        if file not in self.dataReplicaCatalog:\n",
        "            self.dataReplicaCatalog[file] = []\n",
        "        if storage not in self.dataReplicaCatalog[file]:\n",
        "            self.dataReplicaCatalog[file].append(storage)"
      ],
      "metadata": {
        "id": "mHZoiDdQIqwy"
      },
      "id": "mHZoiDdQIqwy",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from enum import Enum\n",
        "from xml.etree import ElementTree as ET\n",
        "\n",
        "\n",
        "class WorkflowParser:\n",
        "    def __init__(self, userId, daxPath):\n",
        "        self.userId = userId\n",
        "        self.mName2Task = {}\n",
        "        self.daxPath = daxPath\n",
        "        self.daxPaths = []\n",
        "        self.jobIdStartsFrom = 1\n",
        "        self.taskList = []\n",
        "        self.transferCosts = {}\n",
        "\n",
        "    def get_task_list(self):\n",
        "        return self.taskList\n",
        "    def get_transfer_cost(self):\n",
        "        return self.transferCosts\n",
        "    def set_task_list(self, task_list):\n",
        "        self.taskList = task_list\n",
        "\n",
        "    def parse(self):\n",
        "        if self.daxPath:\n",
        "            self.parse_xml_file(self.daxPath)\n",
        "        elif self.daxPaths:\n",
        "            for path in self.daxPaths:\n",
        "                self.parse_xml_file(path)\n",
        "\n",
        "    def set_depth(self, task, depth):\n",
        "        if depth > task.getDepth():\n",
        "            task.setDepth(depth)\n",
        "        for cTask in task.getChildList():\n",
        "            self.set_depth(cTask, task.getDepth() + 1)\n",
        "\n",
        "    def parse_xml_file(self, path):\n",
        "        r=ReplicaCatalog()\n",
        "        try:\n",
        "            tree = ET.parse(path)\n",
        "            root = tree.getroot()\n",
        "            for node in root:\n",
        "\n",
        "              if node.tag == \"{http://pegasus.isi.edu/schema/DAX}job\":\n",
        "                length = 0\n",
        "                nodeName = node.get(\"id\")\n",
        "                nodeType = node.get(\"name\")\n",
        "\n",
        "\n",
        "\n",
        "                runtime = 0.1\n",
        "                nodeTime = node.get(\"runtime\")\n",
        "                if nodeTime is not None:\n",
        "                    runtime = 1000*float(nodeTime)\n",
        "                    if runtime < 100:\n",
        "                        runtime = 100\n",
        "                    length = int(runtime)\n",
        "                else:\n",
        "                    print(f\"Cannot find runtime for {nodeName}, set it to be 0\")\n",
        "\n",
        "\n",
        "                mFileList = []\n",
        "                for file in node.findall(\"{http://pegasus.isi.edu/schema/DAX}uses\"):\n",
        "                    fileName = file.get(\"name\")\n",
        "                    if fileName is None:\n",
        "                        fileName = file.get(\"file\")\n",
        "                    if fileName is None:\n",
        "                        print(\"Error in parsing xml\")\n",
        "\n",
        "                    inout = file.get(\"link\")\n",
        "                    size = 0.0\n",
        "                    fileSize = file.get(\"size\")\n",
        "                    if fileSize is not None:\n",
        "                        size = float(fileSize)\n",
        "                    else:\n",
        "                        print(f\"File Size not found for {fileName}\")\n",
        "\n",
        "                    if size == 0:\n",
        "                        size = 1\n",
        "                    type=FileType.NONE\n",
        "                    if inout == \"input\":\n",
        "                        type = FileType.INPUT\n",
        "                    elif inout == \"output\":\n",
        "                        type = FileType.OUTPUT\n",
        "                    else:\n",
        "                        print(\"Parsing Error\")\n",
        "                    tFile = None\n",
        "\n",
        "\n",
        "                    if size < 0:\n",
        "                       size = -size\n",
        "                       print(\"Size is negative, assuming it is a parser error\")\n",
        "\n",
        "\n",
        "                    if type == FileType.OUTPUT:\n",
        "                       tFile = FileItem(fileName, size)\n",
        "                    elif r.containsFile(fileName):\n",
        "                       tFile = r.getFile(fileName)\n",
        "                    else:\n",
        "                       tFile = FileItem(fileName, size)\n",
        "                       r.setFile(fileName, tFile)\n",
        "\n",
        "                    tFile.setType(type)\n",
        "                    mFileList.append(tFile)\n",
        "\n",
        "\n",
        "\n",
        "                task = Task(nodeName,self.jobIdStartsFrom, length)\n",
        "                self.jobIdStartsFrom += 1\n",
        "                task.setType(nodeType);\n",
        "                # task.setUserId(self.userId);\n",
        "                task.setFileList(mFileList)\n",
        "                self.get_task_list().append(task)\n",
        "                self.mName2Task[nodeName] = task\n",
        "                # for file in mFileList:\n",
        "                #    task.addRequired\n",
        "\n",
        "              elif node.tag == \"{http://pegasus.isi.edu/schema/DAX}child\":\n",
        "                child_name = node.get(\"ref\")\n",
        "                if child_name in self.mName2Task:\n",
        "                    child_task = self.mName2Task[child_name]\n",
        "\n",
        "                    for parent in node.findall(\"{http://pegasus.isi.edu/schema/DAX}parent\"):\n",
        "                        parent_name = parent.get(\"ref\")\n",
        "                        if parent_name in self.mName2Task:\n",
        "                            parent_task = self.mName2Task[parent_name]\n",
        "                            child_task.addParent(parent_task)\n",
        "                            parent_task.addChild(child_task)\n",
        "\n",
        "\n",
        "            roots = []\n",
        "\n",
        "            for task in self.mName2Task.values():\n",
        "                task.setDepth(0)\n",
        "                if not task.parentList:\n",
        "                    roots.append(task)\n",
        "\n",
        "            for root_task in roots:\n",
        "                self.set_depth(root_task, 1)\n",
        "\n",
        "            self.mName2Task.clear()\n",
        "\n",
        "        except ET.ParseError:\n",
        "            print(\"3\")\n",
        "            print(\"XML Parse Error; Please make sure your DAX file is valid\")\n",
        "\n",
        "        except IOError:\n",
        "            print(\"4\")\n",
        "            print(\"IO Error; Please make sure the DAX path is correctly set in your config file\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"5\")\n",
        "            print(\"Parsing Exception:\", str(e))\n",
        "\n",
        "    def CalculateTransferCosts(self):\n",
        "      for task1 in self.taskList:\n",
        "        taskTransferCosts = {}\n",
        "\n",
        "        for task2 in self.taskList:\n",
        "            taskTransferCosts[task2] = 0.0\n",
        "        self.transferCosts[task1] = taskTransferCosts\n",
        "      for parent in self.taskList:\n",
        "        for child in parent.getChildList():\n",
        "            self.transferCosts[parent][child] = self.calculateTransferCost(parent, child)\n",
        "\n",
        "    def calculateTransferCost(self, parent, child):\n",
        "      parentFiles = parent.getFileList()\n",
        "      childFiles = child.getFileList()\n",
        "      acc = 0.0\n",
        "      # print(\"Len: \",len(parentFiles))\n",
        "      for parentFile in parentFiles:\n",
        "          # print(parentFile.getType())\n",
        "          if parentFile.getType() != FileType.OUTPUT:\n",
        "              continue\n",
        "          for childFile in childFiles:\n",
        "\n",
        "              if childFile.getType() == FileType.INPUT and childFile.getName() == parentFile.getName():\n",
        "                  acc += childFile.getSize()\n",
        "                  break\n",
        "      return acc\n"
      ],
      "metadata": {
        "id": "xsMo-KVFIrR6"
      },
      "id": "xsMo-KVFIrR6",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daxPath = \"/content/drive/MyDrive/BTP/CyberShake_100.xml\"\n",
        "a=WorkflowParser(1, daxPath)\n",
        "a.parse()\n",
        "a.CalculateTransferCosts()\n",
        "# x = a.get_transfer_cost()\n",
        "# for task in a.get_task_list():\n",
        "#   for t in a.get_task_list():\n",
        "#     if x[task][t] != 0.0:\n",
        "#       print(\"Parent: \", task.taskId)\n",
        "#       print(\"Child: \", t.taskId)\n",
        "#       print(\"transferCost : \", x[task][t])"
      ],
      "metadata": {
        "id": "PnumpgciIsB5"
      },
      "id": "PnumpgciIsB5",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "40b0c192",
      "metadata": {
        "id": "40b0c192"
      },
      "source": [
        "## Creating the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "0d50611c",
      "metadata": {
        "id": "0d50611c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a120c72b-2a4f-46a6-88da-b949e1419d36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n  for every task, find out all suitable vms, create list of suitable vms, allocate to any one of them randomly\\n  keep a list of vm occupied and vm time score.\\n  while allocating tasks randomly to suitable vms, check it's availibility, if it's unavailable, allocate the task to some other random location\\n  if all of the locations are unavailable, return unallocated message. Do this repeatedly until makespan is minimized.\\n  OR KEEP ALLOCATING VMS ONCE A BATCH.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "#ENVIRONMENT\n",
        "\n",
        "class Datacenter:\n",
        "  def __init__(self, name, location, memory, cost_per_hour, cost_per_memory, bandwidth): #cost in Rs, memory in GBs, #Cost_per_memory strorage, BW,\n",
        "    self.name = name\n",
        "    self.location = location\n",
        "    self.memory = memory\n",
        "    self.cost_per_hour = cost_per_hour\n",
        "    self.cost_per_memory = cost_per_memory\n",
        "    self.bandwidth = bandwidth\n",
        "\n",
        "  def add_host(self, host):\n",
        "    self.hosts.append(host)\n",
        "\n",
        "  def get_hosts(self):\n",
        "    return self.hosts\n",
        "\n",
        "  def show_hosts(self):\n",
        "    print(self.hosts)\n",
        "#Type List: MIPS,ID\n",
        "PE_Type_list = {\n",
        "    '1':\n",
        "    {\n",
        "        'MIPS': 100\n",
        "    },\n",
        "    '2':\n",
        "    {\n",
        "        'MIPS': 50\n",
        "    },\n",
        "    '3':\n",
        "    {\n",
        "        'MIPS': 10\n",
        "    }\n",
        "}\n",
        "\n",
        "class Host:\n",
        "  def __init__(self, name, Datacenter, cpu_cores, memory, ram, pe_type, bandwidth):#RAM, BW,Storage,PE ()Type List\n",
        "    self.name = name\n",
        "    self.Datacenter = Datacenter\n",
        "    self.cpu_cores = cpu_cores\n",
        "    self.memory = memory\n",
        "    self.ram = ram\n",
        "    self.pe_type = pe_type\n",
        "    self.bandwidth = bandwidth\n",
        "    self.vms = []\n",
        "\n",
        "  def add_vm(self, vm):\n",
        "    self.vms.append(vm)\n",
        "\n",
        "  def get_mips(self, pe_type):\n",
        "    return PE_Type_List[pe_type][0]\n",
        "\n",
        "  def get_vms(self):\n",
        "    return self.vms\n",
        "\n",
        "VM_type = { #Task_Memory,\n",
        "    'Type_1': {\n",
        "          'Task_Memory' : 256,\n",
        "          'mips' : 1000,\n",
        "          'cost' : 0.10,\n",
        "          'maxFreq' : 1.0,\n",
        "          'minFreq' : 0.50,\n",
        "          'minVoltage' : 5.0,\n",
        "          'maxVoltage' : 7.0,\n",
        "          'lambda' : 0.000150\n",
        "    },\n",
        "    'Type_2': {\n",
        "          'Task_Memory' : 512,\n",
        "          'mips' : 1500,\n",
        "          'cost' : 0.20,\n",
        "          'maxFreq' : 1.5,\n",
        "          'minFreq' : 0.75,\n",
        "          'minVoltage' : 7.0,\n",
        "          'maxVoltage' : 9.0,\n",
        "          'lambda' : 0.000100\n",
        "        },\n",
        "    'Type_3':\n",
        "        {\n",
        "          'Task_Memory' : 1024,\n",
        "          'mips' : 2000,\n",
        "          'cost' : 0.32,\n",
        "          'maxFreq' : 2.0,\n",
        "          'minFreq' : 1.00,\n",
        "          'minVoltage' : 9.0,\n",
        "          'maxVoltage' : 11.0,\n",
        "          'lambda' : 0.000080\n",
        "        },\n",
        "    'Type_4':\n",
        "        {\n",
        "          'Task_Memory' : 500,\n",
        "          'mips' : 2500,\n",
        "          'cost' : 0.46,\n",
        "          'maxFreq' : 2.5,\n",
        "          'minFreq' : 1.25,\n",
        "          'minVoltage' : 11.0,\n",
        "          'maxVoltage' : 13.0,\n",
        "          'lambda' : 0.000045\n",
        "        },\n",
        "    'Type_5':\n",
        "        {\n",
        "          'Task_Memory' : 560,\n",
        "          'mips' : 3000,\n",
        "          'cost' : 0.58,\n",
        "          'maxFreq' : 3.0,\n",
        "          'minFreq' : 1.50,\n",
        "          'minVoltage' : 13,\n",
        "          'maxVoltage' : 15,\n",
        "          'lambda' : 0.000040\n",
        "        },\n",
        "    'Type_6':\n",
        "        {\n",
        "          'Task_Memory' : 250,\n",
        "          'mips' : 3500,\n",
        "          'cost' : 0.73,\n",
        "          'maxFreq' : 3.5,\n",
        "          'minFreq' : 1.75,\n",
        "          'minVoltage' : 15,\n",
        "          'maxVoltage' : 17,\n",
        "          'lambda' : 0.000025\n",
        "        },\n",
        "    'Type_7':\n",
        "        {\n",
        "          'Task_Memory' : 150,\n",
        "          'mips' : 4000,\n",
        "          'cost' : 0.9,\n",
        "          'maxFreq' : 4.0,\n",
        "          'minFreq' : 2.00,\n",
        "          'minVoltage' : 17,\n",
        "          'maxVoltage' : 19,\n",
        "          'lambda' : 0.000010\n",
        "        },\n",
        "    'Type_8':\n",
        "        {\n",
        "          'Task_Memory' : 750,\n",
        "          'mips' : 4500,\n",
        "          'cost' : 1.05,\n",
        "          'maxFreq' : 4.5,\n",
        "          'minFreq' : 2.25,\n",
        "          'minVoltage' : 19,\n",
        "          'maxVoltage' : 21,\n",
        "          'lambda' : 0.000005\n",
        "        },\n",
        "    'Type_9':\n",
        "        {\n",
        "          'Task_Memory' : 2048,\n",
        "          'mips' : 500,\n",
        "          'cost' : 1.40,\n",
        "          'maxFreq' : 5.5,\n",
        "          'minFreq' : 2.75,\n",
        "          'minVoltage' : 23,\n",
        "          'maxVoltage' : 25,\n",
        "          'lambda' : 0.000001\n",
        "        }\n",
        "\n",
        "}\n",
        "\n",
        "AWS_VM_type = {\n",
        "    'Type_1':\n",
        "    {\n",
        "        'Task_Memory' : 60,#GiB\n",
        "          'cost' : 1.591,\n",
        "          'PE' : 36,\n",
        "          'Network+Performance' : \"10 Gigabit\",\n",
        "          'Storage' : \"EBS\"\n",
        "    },\n",
        "    'Type_2':\n",
        "    {\n",
        "        'Task_Memory' : 30,#GiB\n",
        "          'cost' : 0.786,\n",
        "          'PE' : 16,\n",
        "          'Network+Performance' : \"High\",\n",
        "          'Storage' : \"EBS\"\n",
        "    },\n",
        "    'Type_3':\n",
        "    {\n",
        "        'Task_Memory' : 15,#GiB\n",
        "          'cost' : 0.398,\n",
        "          'PE' : 8,\n",
        "          'Network+Performance' : \"High\",\n",
        "          'Storage' : \"EBS\"\n",
        "    },\n",
        "    'Type_4':\n",
        "    {\n",
        "        'Task_Memory' : 7.5,#GiB\n",
        "          'cost' : 0.198,\n",
        "          'PE' : 4,\n",
        "          'Network+Performance' : \"High\",\n",
        "          'Storage' : \"EBS\"\n",
        "    },\n",
        "    'Type_5':\n",
        "    {\n",
        "        'Task_Memory' : 3.75,#GiB\n",
        "          'cost' : 0.10,\n",
        "          'PE' : 2,\n",
        "          'Network+Performance' : \"Moderate\",\n",
        "          'Storage' : \"EBS\"\n",
        "    }\n",
        "}\n",
        "\n",
        "class VM:\n",
        "  def __init__(self, name, Host, Type):\n",
        "    self.name = name\n",
        "    self.Host = Host\n",
        "    self.Type = Type\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def check_memory(datacenter, host_list):\n",
        "    datacenter_memory=datacenter.memory\n",
        "    host_memory=0\n",
        "    for _ in host_list :\n",
        "      host_memory += _.memory\n",
        "    if host_memory > datacenter_memory :\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "def create_suitable_vms(task_memory, vm_memory):\n",
        "    suitable_vms = []\n",
        "    for t in task_memory:\n",
        "        suitable_vms_for_task = []\n",
        "        for v in range (len(vm_memory)):\n",
        "            if t <= vm_memory[v]:\n",
        "                suitable_vms_for_task.append(v)\n",
        "        suitable_vms.append(suitable_vms_for_task)\n",
        "    return suitable_vms\n",
        "\n",
        "\n",
        "class VMAllocationEnv:\n",
        "    def __init__(self, no_of_tasks, vm_list, task_list, task_lengths, datacenter, workflow):\n",
        "        super().__init__()\n",
        "        self.task_lengths = task_lengths\n",
        "        self.task_list = task_list\n",
        "        self.no_of_tasks = no_of_tasks\n",
        "        self.no_of_vms = len(vm_list)\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(no_of_vms, no_of_tasks), dtype=np.float32)\n",
        "        # x,y = random.randint(0, len(action_space) - 1),random.randint(0, len(action_space[0]) - 1)\n",
        "        self.state = np.zeros((no_of_vms, no_of_tasks), dtype = int)\n",
        "        self.datacenter = datacenter\n",
        "        self.workflow = workflow\n",
        "\n",
        "    def action_space(self, task_id):\n",
        "      x,y = task_id-1, (random.randint(0, no_of_vms-1))\n",
        "      self.state[y][x]=1\n",
        "      return [x,y]\n",
        "\n",
        "    def calculate_reward(self, state, action, task_lengths,task,tcostMap):\n",
        "        next_state = self.get_next_state(state, action, task, tcostMap)\n",
        "        makespan = self.calculate_makespan(next_state, task_lengths, task, tcostMap)\n",
        "        return 1.0/float(makespan)\n",
        "\n",
        "    def get_next_state(self, state, action,task, tcostMap):\n",
        "        vm_idx = action[1]\n",
        "        task_idx = action[0]\n",
        "        next_state = state\n",
        "        # queue = []\n",
        "        # queue.append(a.taskList)\n",
        "        # for i in queue:\n",
        "        #   if next_state[vm_idx][task.taskId-1]\n",
        "        # print(\"n_s: \",next_state)\n",
        "        # print(\"::\", next_state[0])\n",
        "        # print(\":::\", next_state[1])\n",
        "        res = 0.0\n",
        "\n",
        "        for i in range(len(next_state)):\n",
        "            # print(next_state[i][task_idx])\n",
        "            if (next_state[i][task_idx] == 1):\n",
        "                next_state[i][task_idx] = 0\n",
        "            next_state[vm_idx][task_idx] = 1\n",
        "        for parent in task.getParentList():\n",
        "          i = parent.taskId-1\n",
        "          for j in range(len(state)):\n",
        "            if state[j][i]==1 and j != vm_idx :\n",
        "              x = self.workflow.get_transfer_cost()\n",
        "              res = max(res,x[parent][task])\n",
        "\n",
        "        res = res / 1000000\n",
        "        res = (res * 8)/ self.datacenter.bandwidth\n",
        "        res = res * 1000.0\n",
        "        tcostMap[task.taskId-1] = res\n",
        "        return next_state\n",
        "\n",
        "    def calculate_makespan(self, state, task_lengths, task,tcostMap):\n",
        "        makespan = 0.0\n",
        "        for i in range(len(state)):\n",
        "            time_in_row = 0.0\n",
        "            for j in range(len(state[0])):\n",
        "                if (state[i][j] == 1):\n",
        "                    time_in_row += (task_lengths[j] + tcostMap[j])\n",
        "            makespan = max(makespan, time_in_row)\n",
        "        # print(\"Makespan in env : \", makespan)\n",
        "        return makespan\n",
        "\n",
        "    def are_all_assigned(self, state): #true if f==no_of_tasks\n",
        "        f = 0\n",
        "        # print(\"State in step: \", state)\n",
        "        for i in range(len(state[0])):\n",
        "            for j in range(len(state)):\n",
        "                if (state[j][i] == 1):\n",
        "                    f += 1\n",
        "        if (f >= self.no_of_tasks):\n",
        "                # print(\"All are assigned!\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def step(self, action, task, tcostMap):\n",
        "        reward = self.calculate_reward(self.state, action, self.task_lengths,task, tcostMap)\n",
        "        self.state = self.get_next_state(self.state, action, task, tcostMap)\n",
        "        done = self.are_all_assigned(self.state)\n",
        "        truncated = False\n",
        "        info = {}\n",
        "        # print(\"Step Called!\")\n",
        "        # print(self.state, done)\n",
        "        return self.state, reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.zeros((self.no_of_vms, self.no_of_tasks), dtype = int)\n",
        "#       self.state = self.state.flatten()\n",
        "        # print(self.state)\n",
        "        return self.state\n",
        "\n",
        "# task_list = [\n",
        "#     Task(\"task1\", 1024, 1000,1), #name, memory, length, PE\n",
        "#     Task(\"task2\", 512, 500,1),\n",
        "#     Task(\"task3\", 256, 250,1),\n",
        "#     Task(\"task4\", 128, 100,1),\n",
        "#     Task(\"task5\", 124, 190,1),\n",
        "#     Task(\"task6\", 500, 10,1),\n",
        "#     Task(\"task7\", 256, 20,1),\n",
        "#     Task(\"task8\", 128, 130,1),\n",
        "#     Task(\"task9\", 1024, 240,1),\n",
        "#     Task(\"task10\", 512, 550,1),\n",
        "#     Task(\"task11\", 256, 210,1),\n",
        "#     Task(\"task12\", 128, 690,1),\n",
        "#     Task(\"task13\", 156, 110,1),\n",
        "#     Task(\"task14\", 128, 620,1)\n",
        "# ]\n",
        "\n",
        "# task_memory = []\n",
        "# vm_memory = []\n",
        "# for _ in vm_list:\n",
        "#   vm_memory.append(VM_type[_.Type]['Task_Memory'])\n",
        "# for _ in task_list:\n",
        "#   task_memory.append(_.memory)\n",
        "\n",
        "# print(\"VM Memory :\", vm_memory)\n",
        "# print(\"Task Memory :\", task_memory)\n",
        "\n",
        "# suitable_vms = create_suitable_vms(task_memory, vm_memory)\n",
        "# print(\"Suitable VMs:\" , suitable_vms)\n",
        "\n",
        "\n",
        "# vm_available = [0] * len(vm_list)\n",
        "\n",
        "# def allocate_task(task, vms, task_memory, vm_memory):\n",
        "#     # suitable_vms = create_suitable_vms(task_memory, vm_memory)\n",
        "#     vm = None\n",
        "#     # Randomly select a VM from the suitable VMs\n",
        "#     index = random.randint(0, len(suitable_vms[task]) - 1)\n",
        "#     vm_index = suitable_vms[task][index]\n",
        "#     if(vm_available[vm_index]==0):\n",
        "#       vm = vm_index\n",
        "#       vm_available[vm_index]=1\n",
        "#     # If the task cannot be allocated to any of the suitable VMs, print the message \"Unallocated task\"\n",
        "#     if vm is None:\n",
        "#         print(\"Unallocated task :\", task)\n",
        "#         return None,None\n",
        "#     return vm,vm_index\n",
        "\n",
        "# action_space = array = [[0 for i in range(len(vm_list))] for j in range(len(task_list))]\n",
        "# print(action_space)\n",
        "\n",
        "# def allocate_tasks(tasks, vms, task_memory, vm_memory):\n",
        "#     allocated_tasks = []\n",
        "#     for task in range(len(tasks)):\n",
        "#         vm, vm_index = allocate_task(task, vms, task_memory, vm_memory)\n",
        "#         print(vm_index)\n",
        "#         if vm and vm_index is not None:\n",
        "#             allocated_tasks.append((tasks[task].memory, vm))\n",
        "#             print(task,vm_index,len(action_space))\n",
        "#             print(len(action_space[task]))\n",
        "#             action_space[task][vm_index]=1\n",
        "#     return allocated_tasks\n",
        "\n",
        "# res = allocate_tasks(task_list, vm_list, task_list, task_memory, vm_memory)\n",
        "# print(res)\n",
        "# print(action_space)\n",
        "# create action_space\n",
        "\n",
        "\n",
        "'''\n",
        "  for every task, find out all suitable vms, create list of suitable vms, allocate to any one of them randomly\n",
        "  keep a list of vm occupied and vm time score.\n",
        "  while allocating tasks randomly to suitable vms, check it's availibility, if it's unavailable, allocate the task to some other random location\n",
        "  if all of the locations are unavailable, return unallocated message. Do this repeatedly until makespan is minimized.\n",
        "  OR KEEP ALLOCATING VMS ONCE A BATCH.\n",
        "'''\n",
        "\n",
        "# env = VMAllocationEnv(vm_list, task_list)\n",
        "# env = VMAllocationEnv(no_of_tasks, no_of_vms, a.taskList, task_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "407c66c4",
      "metadata": {
        "id": "407c66c4"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb76062f",
      "metadata": {
        "id": "fb76062f"
      },
      "source": [
        "## Create the policy $\\pi(s)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "15080113",
      "metadata": {
        "id": "15080113"
      },
      "outputs": [],
      "source": [
        "class PolicyNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(no_of_tasks, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc_mu = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tensor(x).float().to(device)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        loc = self.fc_mu(x)\n",
        "        loc = torch.tanh(loc*9)\n",
        "        return loc\n",
        "\n",
        "def Actor(states, task_id, actor):\n",
        "    actor = actor\n",
        "    actor = actor.to(device)\n",
        "    actor_ = actor.to(device)\n",
        "    actor_.requires_grad_(False)\n",
        "    actions = actor(states).cpu().numpy()[0]\n",
        "    # print(\"Actor:\", actions)\n",
        "    action = [task_id-1, random.randint(0, len(states)-1)]\n",
        "\n",
        "    #action = [abs(round(actions[0]*9.45)), abs(round(actions[1]*60.325))]\n",
        "\n",
        "    return action\n",
        "\n",
        "# actor = PolicyNet()\n",
        "# actor = actor.to(device)\n",
        "# actor.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eabfebe",
      "metadata": {
        "id": "3eabfebe"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## Create the value network $v(s)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "b04ff758",
      "metadata": {
        "id": "b04ff758"
      },
      "outputs": [],
      "source": [
        "class ValueNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(no_of_tasks, 64)\n",
        "        self.fc_mu = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tensor(x).float().to(device)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        loc = self.fc_mu(x)\n",
        "        loc = torch.tanh(loc*9)\n",
        "        return loc\n",
        "\n",
        "def Critic(states, task_id, critic):\n",
        "    critic = critic\n",
        "    critic = critic.to(device)\n",
        "    critic_ = critic.to(device)\n",
        "    critic_.requires_grad_(False)\n",
        "    actions = critic(states).cpu().numpy()[0]\n",
        "    # print(\"Critic:\", actions)\n",
        "    action = [task_id-1, random.randint(0, len(states)-1)]\n",
        "    # action = [abs(round(actions[0]*9.45)), abs(round(actions[1]*60.325))]\n",
        "    return action\n",
        "\n",
        "# critic = ValueNet()\n",
        "# critic = critic.to(device)\n",
        "# critic.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "9bc45fb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bc45fb9",
        "outputId": "9ff82c80-ade1-4e36-80ac-688ba28914e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "num_envs = mp.cpu_count()\n",
        "num_envs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a=WorkflowParser(1)\n",
        "# a.parse()"
      ],
      "metadata": {
        "id": "fKd2zuBLImUO"
      },
      "id": "fKd2zuBLImUO",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "88dceced",
      "metadata": {
        "id": "88dceced"
      },
      "source": [
        "## Implement the algorithm\n",
        "</br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "806e5d76",
      "metadata": {
        "id": "806e5d76",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from queue import Queue\n",
        "from tqdm import trange\n",
        "\n",
        "makespan = []\n",
        "\n",
        "def evaluation(workflow, actor, critic, actor_optim, critic_optim, env):\n",
        "\n",
        "  alpha=1e-4\n",
        "  gamma=0.99\n",
        "  reward_records = []\n",
        "  States = []\n",
        "  Final_State = []\n",
        "  actor_loss=[]\n",
        "  critic_loss=[]\n",
        "  final_makespan = []\n",
        "  Task_Allocation = {}\n",
        "  episodes=[]\n",
        "  stats = {'Actor Loss': [], 'Critic Loss': [], 'Returns': []}\n",
        "  advantage = 0\n",
        "  warnings.filterwarnings('ignore')\n",
        "  for i in range(50):\n",
        "      states = torch.from_numpy(env.reset()).float()\n",
        "      # done = False\n",
        "      cum_reward = 0\n",
        "      makespans =[]\n",
        "      ep_return = torch.zeros((num_envs, 1))\n",
        "      I = 1\n",
        "      tcostMap = {}\n",
        "      episodes.append(i)\n",
        "\n",
        "      q = Queue()\n",
        "      for _ in workflow.taskList: #a.tasklist\n",
        "        q.put(_)\n",
        "      #tasks are allocated only if parent tasks are allocated\n",
        "      while q.qsize()>0:\n",
        "          # Taking Action Based on Advantage\n",
        "          x = q.get()\n",
        "          flag=False\n",
        "          for j in x.parentList:\n",
        "            if j.allocated==False:\n",
        "              q.put(x)\n",
        "              flag=True\n",
        "              break\n",
        "          if flag == True:\n",
        "            continue\n",
        "          else:\n",
        "            x.allocated=True\n",
        "            Action = actor(states)[0]\n",
        "            if advantage<=0:\n",
        "                action = Actor(states,x.taskId, actor)\n",
        "            else:\n",
        "                action = Critic(states,x.taskId, critic)\n",
        "            # if action[0]>=10 or action[1]>=60:\n",
        "            #     continue\n",
        "\n",
        "            next_state, reward, done, _ = env.step(action, x, tcostMap)\n",
        "            if done:\n",
        "    #             print('done!')\n",
        "                makespans.append(1/reward)\n",
        "                States.append(states)\n",
        "                cum_reward += reward\n",
        "                break\n",
        "\n",
        "    #         Critic loss\n",
        "            temp =  critic(torch.from_numpy(next_state).float())[:][0]\n",
        "            value = temp\n",
        "            target = reward + gamma * temp\n",
        "            critic_loss = F.mse_loss(value, target)\n",
        "            critic.zero_grad()\n",
        "            critic_optim.step()\n",
        "\n",
        "    #         Advantage Calculation\n",
        "            value = sum(value/10)\n",
        "            target = sum(target/10)\n",
        "    #         value = math.sqrt((value[0]**2+value[1]**2)/2)\n",
        "    #         target = math.sqrt((target[0]**2+target[1]**2)/2)\n",
        "            advantage = (target - value)\n",
        "\n",
        "    #         Actor loss and returns\n",
        "            probs = actor(states)[1]\n",
        "            log_probs = torch.log(probs + 1e-6)\n",
        "            entropy = - torch.sum(probs * log_probs, dim=-1, keepdim=True)\n",
        "            actor_loss = - I * log_probs * advantage - 0.01 * entropy\n",
        "            actor_loss = actor_loss.mean()\n",
        "            actor.zero_grad()\n",
        "            actor_optim.step()\n",
        "            ep_return += reward\n",
        "            states = next_state\n",
        "            I = I * gamma\n",
        "\n",
        "      reward_records.append(cum_reward)\n",
        "      final_makespan.append(min(makespans))\n",
        "      Final_State.append(States[final_makespan.index(min(makespans))])\n",
        "      stats['Actor Loss'].append(actor_loss.item())\n",
        "      stats['Critic Loss'].append(critic_loss.item())\n",
        "      stats['Returns'].append(ep_return.mean().item())\n",
        "  # makespan.append(min(final_makespans))\n",
        "  # print(\"makespan: \", min(final_makespan))\n",
        "  # print(min(final_makespan))\n",
        "  return min(final_makespan)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Client 1:\n",
        "daxPath = \"/content/drive/MyDrive/BTP/CyberShake_100.xml\"\n",
        "a=WorkflowParser(1, daxPath)\n",
        "a.parse()\n",
        "a.CalculateTransferCosts()\n",
        "task_lengths = []\n",
        "for _ in a.taskList:\n",
        "  task_lengths.append(_.taskLength)\n",
        "\n",
        "# print(\"Task_List :\", task_lengths)\n",
        "\n",
        "\n",
        "#vm_list: append vm type uniformly\n",
        "vm_list = [\n",
        "    VM(\"VM1\", \"host1\", VM_type[\"Type_1\"]),\n",
        "    VM(\"VM2\", \"host1\", VM_type[\"Type_2\"]),\n",
        "    VM(\"VM3\", \"host2\", VM_type[\"Type_3\"]),\n",
        "    VM(\"VM4\", \"host2\", VM_type[\"Type_4\"]),\n",
        "    VM(\"VM5\", \"host3\", VM_type[\"Type_1\"]),\n",
        "    VM(\"VM6\", \"host3\", VM_type[\"Type_2\"]),\n",
        "    VM(\"VM7\", \"host4\", VM_type[\"Type_3\"]),\n",
        "    VM(\"VM8\", \"host4\", VM_type[\"Type_4\"]),\n",
        "    VM(\"VM9\", \"host1\", VM_type[\"Type_1\"]),\n",
        "]\n",
        "\n",
        "host_mem = {\n",
        "    \"host1\":[0,0],#(no_of_vms,max_vm_mem)\n",
        "    \"host2\":[0,0],\n",
        "    \"host3\":[0,0],\n",
        "    \"host4\":[0,0]\n",
        "}\n",
        "\n",
        "#updating host memory based on vms's allocated\n",
        "def host_memory(host_mem, vm_list):\n",
        "  for _ in vm_list:\n",
        "    host_mem[_.Host][1]=max(host_mem[_.Host][1] ,_.Type['Task_Memory'])\n",
        "    host_mem[_.Host][0]+=1\n",
        "\n",
        "host_memory(host_mem, vm_list)\n",
        "\n",
        "D2 = Datacenter(\"D2\", \"Bangalore\", 0, 7.5, 7.5, 500) #name, location, memory, cost_per_hour, cost_per_memory, bandwidth\n",
        "\n",
        "host_list = [\n",
        "    Host(\"host1\", D2, 2, host_mem[\"host1\"][1]*host_mem[\"host1\"][0],2,1,10), #name, Datacenter, cpu_cores, memory, ram, pe_type, bandwidth\n",
        "    Host(\"host2\", D2, 4, host_mem[\"host2\"][1]*host_mem[\"host2\"][0],4,2,25),\n",
        "    Host(\"host3\", D2, 8, host_mem[\"host3\"][1]*host_mem[\"host3\"][0],4,3,100),\n",
        "    Host(\"host4\", D2, 16, host_mem[\"host4\"][1]*host_mem[\"host4\"][0],8,4,75)\n",
        "]\n",
        "\n",
        "#updating datacenter based on host's allocated\n",
        "def datacenter_memory(host_mem, vm_list):\n",
        "  mem = 0\n",
        "  for _ in host_list:\n",
        "    mem += _.memory\n",
        "  D2.memory = mem\n",
        "datacenter_memory(host_mem, vm_list)\n",
        "print(\"D2 memory : \", D2.memory)\n",
        "\n",
        "no_of_vms = len(vm_list)\n",
        "no_of_tasks = len(task_lengths)\n",
        "\n",
        "env1 = VMAllocationEnv(no_of_tasks, vm_list, a.taskList, task_lengths, D2, a)\n",
        "actor1 = PolicyNet()\n",
        "actor1 = actor1.to(device)\n",
        "actor1.requires_grad_(False)\n",
        "\n",
        "critic1 = ValueNet()\n",
        "critic1 = critic1.to(device)\n",
        "critic1.requires_grad_(False)\n",
        "\n",
        "actor1_optim = AdamW(actor1.parameters(), lr=0.05)\n",
        "critic1_optim = AdamW(critic1.parameters(), lr=0.05)\n",
        "\n",
        "# print(evaluation(a, actor1, critic1, actor1_optim, critic1_optim, env1)/1000.0)\n",
        "\n",
        "#Client2:\n",
        "daxPath = \"/content/drive/MyDrive/BTP/CyberShake_100.xml\"\n",
        "b=WorkflowParser(2, daxPath)\n",
        "b.parse()\n",
        "b.CalculateTransferCosts()\n",
        "task_lengths = []\n",
        "for _ in b.taskList:\n",
        "  task_lengths.append(_.taskLength)\n",
        "\n",
        "# print(\"Task_List :\", task_lengths)\n",
        "\n",
        "\n",
        "#vm_list: append vm type uniformly\n",
        "vm_list_AWS = [\n",
        "    VM(\"VM1\", \"host1\", AWS_VM_type[\"Type_1\"]),\n",
        "    VM(\"VM2\", \"host1\", AWS_VM_type[\"Type_2\"]),\n",
        "    VM(\"VM3\", \"host2\", AWS_VM_type[\"Type_3\"]),\n",
        "    VM(\"VM4\", \"host2\", AWS_VM_type[\"Type_4\"]),\n",
        "    VM(\"VM5\", \"host3\", AWS_VM_type[\"Type_1\"]),\n",
        "    VM(\"VM6\", \"host3\", AWS_VM_type[\"Type_2\"]),\n",
        "    VM(\"VM7\", \"host4\", AWS_VM_type[\"Type_3\"]),\n",
        "    VM(\"VM8\", \"host4\", AWS_VM_type[\"Type_4\"]),\n",
        "    VM(\"VM9\", \"host1\", AWS_VM_type[\"Type_1\"]),\n",
        "]\n",
        "\n",
        "host_mem_AWS = {\n",
        "    \"host1\":[0,0],#(no_of_vms,max_vm_mem)\n",
        "    \"host2\":[0,0],\n",
        "    \"host3\":[0,0],\n",
        "    \"host4\":[0,0]\n",
        "}\n",
        "\n",
        "def host_memory(host_mem, vm_list):\n",
        "  for _ in vm_list_AWS:\n",
        "    host_mem_AWS[_.Host][1]=max(host_mem_AWS[_.Host][1] ,_.Type['Task_Memory'])\n",
        "    host_mem_AWS[_.Host][0]+=1\n",
        "\n",
        "host_memory(host_mem_AWS, vm_list_AWS)\n",
        "\n",
        "AWS = Datacenter(\"AWS\", \"Bangalore\", 0, 7.5, 7.5, 500) #name, location, memory, cost_per_hour, cost_per_memory, bandwidth\n",
        "\n",
        "host_list_AWS = [\n",
        "    Host(\"host1\", AWS, 2, host_mem_AWS[\"host1\"][1]*host_mem_AWS[\"host1\"][0],2,1,10), #name, Datacenter, cpu_cores, memory, ram, pe_type, bandwidth\n",
        "    Host(\"host2\", AWS, 4, host_mem_AWS[\"host2\"][1]*host_mem_AWS[\"host2\"][0],4,2,25),\n",
        "    Host(\"host3\", AWS, 8, host_mem_AWS[\"host3\"][1]*host_mem_AWS[\"host3\"][0],4,3,100),\n",
        "    Host(\"host4\", AWS, 16, host_mem_AWS[\"host4\"][1]*host_mem_AWS[\"host4\"][0],8,4,75)\n",
        "]\n",
        "\n",
        "def datacenter_memory(host_mem_AWS, vm_list_AWS):\n",
        "  mem = 0\n",
        "  for _ in host_list_AWS:\n",
        "    mem += _.memory\n",
        "  AWS.memory = mem\n",
        "datacenter_memory(host_mem_AWS, vm_list_AWS)\n",
        "print(\"AWS memory : \", AWS.memory)\n",
        "\n",
        "no_of_vms = len(vm_list_AWS)\n",
        "no_of_tasks = len(task_lengths)\n",
        "\n",
        "env2 = VMAllocationEnv(no_of_tasks, vm_list_AWS, b.taskList, task_lengths,AWS,b)\n",
        "actor2 = PolicyNet()\n",
        "actor2 = actor2.to(device)\n",
        "actor2.requires_grad_(False)\n",
        "\n",
        "critic2 = ValueNet()\n",
        "critic2 = critic2.to(device)\n",
        "critic2.requires_grad_(False)\n",
        "\n",
        "actor2_optim = AdamW(actor2.parameters(), lr=0.05)\n",
        "critic2_optim = AdamW(critic2.parameters(), lr=0.05)\n",
        "\n",
        "# evaluation(b, actor2, critic2, actor2_optim, critic2_optim,env2)\n",
        "\n",
        "#Federated Model\n",
        "\n",
        "actor_fed = PolicyNet()\n",
        "actor_fed = actor_fed.to(device)\n",
        "actor_fed.requires_grad_(False)\n",
        "\n",
        "\n",
        "critic_fed = ValueNet()\n",
        "critic_fed = critic_fed.to(device)\n",
        "critic_fed.requires_grad_(False)\n",
        "\n",
        "actor_fed_optim = AdamW(actor_fed.parameters(), lr=0.05)\n",
        "critic_fed_optim = AdamW(critic_fed.parameters(), lr=0.05)\n",
        "\n"
      ],
      "metadata": {
        "id": "eI_K__5ObwbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "255b756e-7c86-4760-90a6-dce99b6a1e4b"
      },
      "id": "eI_K__5ObwbJ",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D2 memory :  6656\n",
            "AWS memory :  360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "aggregator_epochs = 20\n",
        "\n",
        "number_of_clients = 2\n",
        "\n",
        "from tqdm import trange\n",
        "# client_actor_weights = {client: None for client in range(number_of_clients)}\n",
        "# client_critic_weights = {client: None for client in range(number_of_clients)}\n",
        "\n",
        "#list of makespan obtained in each epoch\n",
        "makespan1=[]\n",
        "makespan2=[]\n",
        "\n",
        "for epoch in trange(aggregator_epochs, desc =\"Aggregator Model\"):\n",
        "\n",
        "#training the client models locally\n",
        "  print(\"\\nMakepsan after epoch:\",epoch)\n",
        "  x=evaluation(a, actor1, critic1, actor1_optim, critic1_optim,env1)\n",
        "  print(\"Client 1: \", x/1000) #tasklength was multiplied by 1000 when workflow was parsed\n",
        "  makespan1.append(x/1000)\n",
        "  y=evaluation(b, actor2, critic2, actor2_optim, critic2_optim,env2)\n",
        "  print(\"Client 2: \", y/1000)\n",
        "  makespan2.append(y/1000)\n",
        "\n",
        "#extracting the weights of the client models\n",
        "  #Actor\n",
        "  actor1_state_dict = actor1.state_dict()\n",
        "  actor2_state_dict = actor2.state_dict()\n",
        "\n",
        "#taking the mean of weights of both the client models\n",
        "  actor_state_dict = {}\n",
        "  for key in actor1_state_dict:\n",
        "      if key in actor2_state_dict:\n",
        "          actor_state_dict[key] = (actor1_state_dict[key] + actor2_state_dict[key]) / 2.0\n",
        "      else:\n",
        "          actor_state_dict[key] = actor_state_dict[key]\n",
        "\n",
        "  # for key in state_dict2:\n",
        "  #     if key not in state_dict1:\n",
        "  #         mean_state_dict[key] = state_dict2[key]\n",
        "\n",
        "\n",
        "  #updating the weights of federated model with the mean of weights of client models\n",
        "  actor_fed.load_state_dict(actor_state_dict)\n",
        "\n",
        "  #Critic\n",
        "  critic1_state_dict = critic1.state_dict()\n",
        "  critic2_state_dict = critic2.state_dict()\n",
        "\n",
        "  critic_state_dict = {}\n",
        "  for key in critic1_state_dict:\n",
        "      if key in critic2_state_dict:\n",
        "          critic_state_dict[key] = (critic1_state_dict[key] + critic2_state_dict[key]) / 2.0\n",
        "      else:\n",
        "          critic_state_dict[key] = critic_state_dict[key]\n",
        "\n",
        "  # for key in state_dict2:\n",
        "  #     if key not in state_dict1:\n",
        "  #         mean_state_dict[key] = state_dict2[key]\n",
        "  critic_fed.load_state_dict(critic_state_dict)\n",
        "\n",
        "#updating the weights of the both the client model with the weight of federated model\n",
        "  actor1.load_state_dict(actor_fed.state_dict())\n",
        "  actor2.load_state_dict(actor_fed.state_dict())\n",
        "  critic1.load_state_dict(critic_fed.state_dict())\n",
        "  critic2.load_state_dict(critic_fed.state_dict())\n",
        "\n",
        "#Average makespan after the aggregator epochs\n",
        "print(\"Makespan after federated learning of Client 1: \",sum(makespan1)/len(makespan1))\n",
        "print(\"Makespan after federated learning of Client 2: \",sum(makespan2)/len(makespan2))\n"
      ],
      "metadata": {
        "id": "WaN5eGgB6Is4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3a5577-b564-4648-c22b-d9f44a43b136"
      },
      "id": "WaN5eGgB6Is4",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:   0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Makepsan after epoch: 0\n",
            "Client 1:  505.977879584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:   5%|â–Œ         | 1/20 [00:20<06:29, 20.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  484.150335968\n",
            "\n",
            "Makepsan after epoch: 1\n",
            "Client 1:  519.4807388160001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  10%|â–ˆ         | 2/20 [00:41<06:18, 21.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  530.8046156799999\n",
            "\n",
            "Makepsan after epoch: 2\n",
            "Client 1:  510.09420137600006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  15%|â–ˆâ–Œ        | 3/20 [01:03<06:05, 21.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  509.214768608\n",
            "\n",
            "Makepsan after epoch: 3\n",
            "Client 1:  471.5329505600001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  20%|â–ˆâ–ˆ        | 4/20 [01:24<05:36, 21.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  517.4957165440001\n",
            "\n",
            "Makepsan after epoch: 4\n",
            "Client 1:  543.3453560319999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [01:44<05:12, 20.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  522.779033216\n",
            "\n",
            "Makepsan after epoch: 5\n",
            "Client 1:  521.3945976320001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [02:07<05:00, 21.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  480.37741126400005\n",
            "\n",
            "Makepsan after epoch: 6\n",
            "Client 1:  515.83371008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [02:27<04:35, 21.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  499.4039261120001\n",
            "\n",
            "Makepsan after epoch: 7\n",
            "Client 1:  514.4919231360001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [02:48<04:10, 20.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  518.707851072\n",
            "\n",
            "Makepsan after epoch: 8\n",
            "Client 1:  494.06023286400006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [03:09<03:49, 20.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  474.8052908480001\n",
            "\n",
            "Makepsan after epoch: 9\n",
            "Client 1:  521.5666106560001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [03:31<03:33, 21.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  490.59125177600004\n",
            "\n",
            "Makepsan after epoch: 10\n",
            "Client 1:  522.3686468480001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [03:51<03:09, 21.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  515.196302208\n",
            "\n",
            "Makepsan after epoch: 11\n",
            "Client 1:  515.064150368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [04:12<02:46, 20.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  471.41007984000015\n",
            "\n",
            "Makepsan after epoch: 12\n",
            "Client 1:  525.1444143680001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [04:34<02:29, 21.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  483.9905018560001\n",
            "\n",
            "Makepsan after epoch: 13\n",
            "Client 1:  517.953873856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [04:55<02:06, 21.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  511.33780905600014\n",
            "\n",
            "Makepsan after epoch: 14\n",
            "Client 1:  501.310520704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [05:15<01:44, 20.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  520.48523456\n",
            "\n",
            "Makepsan after epoch: 15\n",
            "Client 1:  492.85015312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [05:36<01:23, 20.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  504.36850550400004\n",
            "\n",
            "Makepsan after epoch: 16\n",
            "Client 1:  455.80155440000004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [05:58<01:03, 21.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  520.0054987200001\n",
            "\n",
            "Makepsan after epoch: 17\n",
            "Client 1:  497.3106989440001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [06:18<00:41, 20.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  480.8191002240001\n",
            "\n",
            "Makepsan after epoch: 18\n",
            "Client 1:  496.05651545600006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAggregator Model:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [06:39<00:20, 20.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  542.0044991039999\n",
            "\n",
            "Makepsan after epoch: 19\n",
            "Client 1:  480.364896096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Aggregator Model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [07:01<00:00, 21.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 2:  512.3107967679999\n",
            "Makespan after federated learning of Client 1:  506.1001812448001\n",
            "Makespan after federated learning of Client 2:  504.51292644640006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}